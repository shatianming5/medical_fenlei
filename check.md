根据您提供的文件内容，以下是整理好的、可直接复制的研究方案全文。我已经为您去除了原本的页码标记和引用标签，并还原了文档的结构与格式（包括公式和表格），以便您编辑使用。

---

# 基于双侧解剖对称性与影像报告语义导向的 3D时序骨CT长尾疾病诊断架构: Bi-CPL研究方案

## 摘要

在医学影像分析领域，利用深度学习进行自动化疾病诊断已取得显著进展，但在处理高分辨率3D体积数据（如颞骨CT）中的罕见病灶（长尾分布）时，现有的全监督学习范式仍面临严峻挑战。颞骨解剖结构精细复杂，且常见病（如慢性化脓性中耳炎）与罕见病（如胆固醇肉芽肿）在数据量上呈现极端的类别不平衡，导致模型对尾部类别的识别能力匮乏。此外，获取大规模的体素级标注数据成本高昂且不切实际。针对上述问题，本研究提出了一种无需额外人工标注、仅基于现有3D CT影像与非结构化放射学报告的创新深度学习框架——**双侧对比原型学习网络 (Bi-Lateral Contrastive Prototype Learning, Bi-CPL)**。

Bi-CPL架构的核心创新在于三个维度：首先，利用人体解剖学的双侧对称性先验，设计基于孪生网络 (Siamese Network) 的3D视觉编码器，通过显式的交叉注意力机制捕捉患侧与健侧的细微差异，从而增强对微小病灶的特征提取能力；其次，构建基于中文医疗预训练语言模型 (CMBERT) 的语义引导模块，深度挖掘放射报告中“影像所见”与“检查结论”的细粒度语义特征，将其映射为高维语义原型；最后，提出文本引导的原型矫正机制，利用医学知识图谱或大语言模型生成的文本描述，为数据匮乏的长尾类别（如胆固醇肉芽肿）合成虚拟原型，实现零样本或少样本分类。本研究方案旨在通过挖掘多模态数据的内在关联，解决医疗影像AI落地中的“数据孤岛”与“长尾失效”痛点，为顶级计算机视觉与医学影像会议（如CVPR、MICCAI）提供具有高度临床价值与技术创新性的Oral级别研究成果。

---

## 1. 绪论

### 1.1 临床背景与研究动机

颞骨高分辨率CT (HRCT) 是耳科疾病诊断的金标准，能够清晰显示中耳乳突、听骨链、面神经管及内耳迷路等微细结构。在临床实践中，放射科医生面临的主要挑战在于病种繁多且分布极不均匀。根据流行病学统计及日常临床数据流，慢性化脓性中耳炎 (Chronic Suppurative Otitis Media, CSOM) 和分泌性中耳炎 (Secretory Otitis Media, SOM) 占据了绝大多数病例，构成了数据分布的“头部”。相比之下，中耳胆脂瘤 (Cholesteatoma) 虽然临床重要性极高，但其发病率相对较低，而诸如胆固醇肉芽肿 (Cholesterol Granuloma)、面神经鞘瘤、颈静脉球瘤等病变则属于典型的“长尾”类别。

在现有的提供的4000余例数据样本中，绝大多数标签集中在“慢性化脓性中耳炎”、“中耳胆脂瘤”和“分泌性中耳炎”以及“正常”类别。标记为“4”或特定提及“胆固醇肉芽肿”的样本极少甚至在训练集中缺失。这种长尾分布 (Long-Tailed Distribution) 导致传统的监督学习模型在训练过程中过度拟合头部类别，对尾部类别产生严重的偏见。例如，模型极易将具有软组织密度的胆固醇肉芽肿误判为常见的中耳炎，因为两者在单纯的视觉特征上存在重叠，而模型倾向于预测先验概率更高的类别。然而，这种误诊在临床上是不可接受的，因为两者的治疗方案截然不同：中耳炎可能仅需药物治疗或简单的鼓膜修补，而胆固醇肉芽肿或胆脂瘤则可能涉及复杂的颅底手术。

此外，现有的模型架构往往忽略了医生阅片时的两个关键认知过程：

1. **双侧对比 (Bilateral Comparison):** 医生在判断单侧病变时，几乎总是会参照对侧耳的结构。人体解剖的对称性是一个极强的先验知识，微小的骨质破坏或密度增高在与健侧对比时会变得异常显著。目前的单侧输入模型浪费了这一关键信息。
2. **语义推理 (Semantic Reasoning):** 医生并非仅凭图像像素做判断，而是结合了深厚的病理生理学知识。例如，在报告中描述“骨质破坏边界清楚锐利”强烈指向胆脂瘤，而“膨胀性改变、骨质变薄但完整”则可能指向胆固醇肉芽肿。现有的纯视觉模型无法利用这些蕴含在文本报告中的诊断逻辑。

因此，本研究旨在设计一种能够同时利用双侧影像对称性和文本报告语义的深度学习框架，在不增加任何人工标注成本的前提下，显著提升模型对长尾疑难病种的诊断能力。

### 1.2 科学问题与挑战

本研究核心解决以下三个科学问题：

1. **如何从非结构化文本中提取有效的监督信号?** 提供的CSV文件中包含了“影像所见”和“检查结论”。这些文本是非结构化的自然语言，包含了大量的解剖学术语、方位描述和否定句式。如何将这些文本转化为能够指导3D视觉模型学习的语义特征，是本研究的首要挑战。
2. **如何克服长尾分布导致的特征坍塌?** 对于样本极少的类别（如胆固醇肉芽肿），模型无法学习到鲁棒的类中心 (Prototype)。如何利用文本描述来“合成”或“校准”这些类别的特征原型，实现从视觉样本匮乏到语义特征丰富的跨越，是解决长尾问题的关键。
3. **如何在3D空间中有效利用对称性先验?** 3D CT数据维度高、计算量大。直接将双侧数据输入网络会成倍增加显存消耗。如何在保证计算效率的前提下，设计有效的双侧特征交互机制，捕捉细微的不对称性，是架构设计的难点。

### 1.3 研究目标与预期贡献

本研究的目标是构建一个端到端的多模态双侧对比原型学习框架 (Bi-CPL)。该框架将实现：

* **零样本/少样本能力:** 即便训练集中没有或仅有极少量胆固醇肉芽肿样本，模型也能通过理解其文本描述（如“膨胀性生长”、“高密度囊肿”）在测试集中将其识别出来。
* **分类性能提升:** 在常见病（胆脂瘤 vs 中耳炎）的鉴别诊断上，通过双侧对比机制，提升对细微骨质破坏的敏感度，从而提高整体分类F1分数。

本研究的主要贡献预计包括：

1. **提出Bi-CPL架构:** 首次将孪生网络 (Siamese Network) 引入3D耳科影像分析，并结合视觉-语言模型 (VLM)，专门针对解剖对称器官的病变检测。
2. **文本引导的原型生成机制:** 提出一种利用放射学报告生成长尾疾病分类原型的策略，解决了医疗影像领域极度缺乏罕见病样本的难题。
3. **挖掘报告数据的价值:** 证明了无需昂贵的体素级标注，仅利用医院现有的PACS系统中的文本报告，即可训练出高性能的3D诊断模型，为医疗AI的低成本落地提供了新范式。

---

## 2. 数据深度分析与挖掘策略

在制定具体算法方案前，必须对现有的数据资产进行详尽的剖析。本研究基于提供的一份包含4000余条脱敏数据的Excel文件（影像学检查.csv）及对应的3D CT影像数据。

### 2.1 文本数据的特征分析

通过对影像学检查.csv的深入挖掘，我们发现“影像所见”和“检查结论”两列文本具有极高的语义密度和规律性，这为自然语言处理 (NLP) 提供了坚实基础。

#### 2.1.1 结构化描述模式

尽管是自由文本，但放射科医生的描述遵循严格的解剖学顺序和逻辑范式。

* **外耳:** 描述外耳道通畅与否（如“双侧外耳道通畅”）。
* **中耳/鼓室:** 描述鼓膜状态（“增厚”、“穿孔”）、鼓室内密度（“软组织密度影”、“气化良好”）。
* **听骨链:** 描述形态与完整性（“听骨链连续”、“骨质吸收”、“破坏”）。
* **乳突:** 描述气化类型（“气化型”、“板障型”、“硬化型”）及气房内状况（“密度增高”、“液平”）。
* **内耳及周围骨质:** 描述半规管、耳蜗形态，以及乙状窦、颈静脉球位置（“高位”）。

这种高度模式化的文本非常适合用于提取属性-实体对 (Attribute-Entity Pairs)。例如，从文本“左侧听小骨骨质吸收”中，可以提取出 <解剖部位: 左侧听小骨, 状态: 骨质吸收>。

#### 2.1.2 关键鉴别特征的文本映射

通过对比不同诊断标签的文本描述，我们发现了区分头部类别与尾部类别的关键语义特征，这些特征将指导我们设计文本编码器的注意力机制。

| 诊断类别 (Label) | 关键文本特征 (Key Semantic Features) | 视觉对应特征 (Visual Correlates) | 典型描述长度 |
| --- | --- | --- | --- |
| **中耳胆脂瘤 (Label 2)**<br>

<br>**慢性化脓性中耳炎 (Label 1)** | “骨质吸收”、“破坏”、“边界清楚锐利”、“鼓室窦口扩大”、“上鼓室扩大”<br>

<br>“鼓膜增厚”、“内陷”、“穿孔”、“硬化型乳突”、“骨皮质毛糙”（非破坏） | 骨质缺损、软组织肿块、边缘锐利<br>

<br>粘膜增厚、乳突硬化、听骨链虽被包绕但骨质多存留 | 长 (250-350字)<br>

<br>中 (150-250字) |
| **分泌性中耳炎 (Label 3)** | “液平”、“气泡”、“充填”、“听小骨形态正常”、“未见骨质破坏” | 鼓室积液、气液平面、骨质完整 | 中 (150-200字) |
| **胆固醇肉芽肿 (目标长尾)** | (基于文献推断) “膨胀性改变”、“骨质变薄”、“边缘光滑”、“高信号”(MRI描述混入) | 囊性病变、骨壁膨胀变薄但不侵蚀 | 极罕见 (无样本) |

* **数据洞察1:** 胆脂瘤与中耳炎的核心区别在于骨质破坏的程度与性质。报告中明确使用了“破坏”、“吸收”与“毛糙”、“完整”等词汇进行区分。我们的模型必须学会关注这些动词。
* **数据洞察2:** 报告中大量存在“双侧”描述（如“双侧乳突呈气化型”），这意味着当描述变为“左侧... 右侧...”的非对称描述时，往往意味着病变。这直接验证了双侧对比学习的必要性。

### 2.2 影像数据的特性与处理策略

* **模态:** 3D CT影像，具有高分辨率（通常512x512xZ），体素各向异性。
* **窗宽窗位:** 颞骨CT需要特定的骨窗 (Window Width: 4000, Window Level: 700) 来观察骨质结构，同时也需要软组织窗来观察炎症填充物。
* **空间一致性:** 由于扫描体位相对固定，通过刚性配准 (Rigid Registration) 可以很容易地将左右耳对齐到标准空间，这为孪生网络的输入预处理提供了便利。

### 2.3 类别分布与长尾问题

根据提供的数据快照，数据分布呈现典型的长尾效应：

* **Head Classes:** 正常 (Label 5), 慢性化脓性中耳炎 (Label 1).
* **Middle Classes:** 分泌性中耳炎 (Label 3), 中耳胆脂瘤 (Label 2).
* **Tail Classes:** 胆固醇肉芽肿 (Label 4, 甚至在提供的数千条数据中未出现), 其他罕见肿瘤 (Label 6).

**策略:** 对于Label 4（胆固醇肉芽肿），由于训练数据中可能完全缺失，我们不能依赖分类器的 Softmax层去学习。我们必须采用**零样本学习 (Zero-Shot Learning)** 策略：即在推理阶段，利用文本编码器生成的“胆固醇肉芽肿”的语义向量作为分类权重，与图像特征进行匹配。如果图像特征表现出“膨胀性”、“囊性”等与文本描述相符的特征，模型应能将其归类为Label 4，即使它从未见过Label 4的图像。

---

## 3. 相关工作综述

### 3.1 医疗视觉-语言预训练 (Med-VLP)

近年来，以CLIP为代表的视觉-语言对比学习框架在通用领域取得了巨大成功。在医疗领域，ConVIRT开创性地提出利用配对的医疗图像和文本报告进行双向对比学习，证明了文本语义能显著提升视觉表征的质量。随后，GLORIA和BioMedCLIP进一步引入了局部-全局对齐机制，解决了医学图像中细微病灶与文本描述的对应问题。
然而，现有的Med-VLP工作大多集中在2D图像（如胸部X光片）上。针对3D体数据的VLP研究相对较少，主要受限于计算资源。Med3DVLM和M3D-LaMed是近期的尝试，它们使用高效的3D Transformer作为视觉骨干，并探索了切片选择策略。本研究将借鉴这些架构，但针对颞骨CT的对称性特点进行专门的改进。

### 3.2 长尾分布与原型学习

解决长尾问题的经典方法包括重采样 (Resampling) 和重加权 (Re-weighting)，但这些方法往往牺牲头部类别的性能。近期，原型学习 (Prototype Learning) 成为主流。该方法主张学习每个类别的中心特征（原型），并通过特征空间中的距离进行分类。
结合VLP，文本引导的原型学习被证明对零样本分类有效。例如，利用LLM生成类别的丰富描述，以此构建更鲁棒的文本原型。对于从未见过的罕见病，只要我们能用文字准确描述其特征，模型就有可能通过语义匹配将其识别出来。

### 3.3 孪生网络与对称性感知

在医学影像中，对称性是一种强先验。Deep Siamese Networks 已被用于检测阿尔茨海默病中的脑部不对称萎缩，以及在乳腺钼靶中通过双侧对比检测异常。在骨科X光中，解剖感知的孪生网络通过对比双侧骨盆结构提高了骨折检测率。
对于颞骨CT，病变（如中耳炎、胆脂瘤）往往破坏了原本的解剖对称性。因此，引入孪生网络结构，显式地计算双侧特征差异 (Difference Map)，是提升模型对细微病变敏感度的有效手段。

---

## 4. 研究方法: Bi-CPL 框架设计

本研究提出的 Bi-CPL (Bi-Lateral Contrastive Prototype Learning) 框架包含三个核心模块：双侧解剖感知3D视觉编码器、放射报告语义增强模块、以及文本引导的对比原型分类器。

### 4.1 模块一：双侧解剖感知3D视觉编码器 (Bilateral Anatomy-Aware Visual Encoder)

该模块旨在从3D CT影像中提取具有判别力的视觉特征，并显式利用双侧对称性。

#### 4.1.1 数据预处理与配准

输入为患者的头部HRCT扫描。

1. **ROI裁剪:** 基于解剖标志点（如半规管）自动定位并裁剪出左、右颞骨区域，大小统一为 （例如 ）。
2. **镜像翻转:** 将右耳图像沿矢状面翻转，使其解剖方向与左耳一致。这样，在理想的健康状态下，左耳体素  应与翻转后的右耳体素  高度相似。

#### 4.1.2 3D 孪生骨干网络 (Siamese 3D Backbone)

我们采用参数共享的孪生网络结构处理  和 。为了平衡性能与显存，骨干网络选用 3D Swin Transformer 或 DCFormer。这些模型利用移动窗口机制或分解卷积，能有效提取局部细粒度特征（如听小骨结构）和全局上下文特征（如乳突气化程度）。
设  为视觉编码器，提取的层级特征为：



其中  表示网络的层级 (Stage)。

#### 4.1.3 非对称感知注意力模块 (Asymmetry-Aware Attention Block, A3B)

这是本架构的核心创新点。我们在孪生网络的每一层之间插入A3B模块，用于交互双侧信息。
传统的孪生网络通常在最后层计算距离，而我们提出在特征提取阶段就引入差异激励 (Difference Excitation)。
对于第  层的特征 ，我们计算差异特征图：



其中  是一个轻量级的卷积层。
然后，生成一个非对称注意力掩码 (Asymmetry Mask):



其中  是 Sigmoid 函数。该掩码在差异显著的区域（如病变区）趋近于1，在对称区域趋近于0。
最后，用该掩码对原始特征进行加权增强：



这一机制迫使网络关注那些“双侧不一致”的区域，这与放射科医生“对比看片”的思维模式完全一致。

### 4.2 模块二：放射报告语义增强模块 (Radiology Report Semantic Enforcement)

该模块负责从提供的非结构化CSV文本中提取结构化的语义信息，构建高质量的文本嵌入 (Text Embeddings)。

#### 4.2.1 文本预处理与编码

使用 Chinese Medical BERT (CMBERT) 作为文本编码器 。该模型已在海量中文医疗文本上预训练，能理解“气化型”、“骨质破坏”等专业术语的语义关联。
输入文本  是“影像所见”和“检查结论”的拼接。输出为文本的全局特征向量 。

#### 4.2.2 实体-属性图构建 (Entity-Attribute Graph Construction)

为了更精细地利用文本，我们不只使用整段文本的 Embedding，而是通过NLP工具提取细粒度的解剖-病变对。
例如，从“左侧听小骨骨质吸收”中提取：

* Entity: 听小骨 (Ossicles)
* Attribute: 骨质吸收 (Bone Absorption)
* Location: 左侧 (Left)
我们将这些三元组转化为一组局部文本特征 ，用于后续与图像的局部区域进行细粒度对齐 (Local Alignment)。这能防止模型仅仅学习到“有病/没病”的粗糙概念，而是真正学会“哪里有病，什么病”。

#### 4.2.3 长尾类别的原型合成 (Text-Guided Prototype Synthesis)

对于数据集中缺失或极少的类别（如Label 4: 胆固醇肉芽肿），我们利用外部医学知识库构建其虚拟文本原型。
我们编写标准的医学描述 Prompt:

* **Prompt (Label 4):** “颞骨岩尖或中耳内的囊性病变，膨胀性生长，边缘光滑锐利，无骨质侵蚀性破坏，MRI T1高信号。检查结论：胆固醇肉芽肿。”
将此描述输入 CMBERT，得到特征向量 。这个向量将作为分类器中代表“胆固醇肉芽肿”的权重向量。

### 4.3 模块三：对比原型对齐与损失函数 (Contrastive Prototype Alignment)

Bi-CPL 摒弃了传统的 Softmax 分类头（全连接层），改用基于原型的分类器。

#### 4.3.1 视觉-文本对比学习 (Vision-Language Contrastive Loss)

在训练阶段，对于头部类别 (Label 1, 2, 3, 5)，我们拥有成对的图像  和报告 。我们使用 InfoNCE Loss 来拉近图像特征  与其对应报告特征  的距离，推远与其他报告的距离。



这一步实现了模态对齐，赋予了视觉特征明确的语义含义。

#### 4.3.2 文本引导的原型分类 (Text-Guided Prototype Classification)

对于分类任务，我们定义  个类别的原型矩阵 。关键在于， 不是随机初始化的，而是由各类的文本原型  初始化的。



在训练过程中，我们允许  微调，但施加约束使其不能偏离文本原型太远。对于缺失的尾部类别 (Label 4)，我们直接固定其权重 。
推理时，计算图像特征  与所有  的余弦相似度，取最大值作为预测结果：


#### 4.3.3 总损失函数


其中  约束：若标签为“正常”，则左右耳特征距离应最小化；若为单侧病变，距离应最大化。

---

## 5. 实验设计与评估

### 5.1 数据集与预处理

* **来源:** 使用提供的4017条数据。
* **划分:** 训练集 (70%)、验证集 (10%)、测试集 (20%)。
* **长尾设置:**
* **设置A (全监督基线):** 仅使用现有的 Label 1, 2, 3, 5 进行训练和测试。
* **设置B (零样本长尾测试):** 人为移除训练集中的 Label 2（胆脂瘤）样本，但在测试集中保留。模型需仅凭文本描述（“骨质破坏”、“软组织影”）在测试集中识别出胆脂瘤。这模拟了对 Label 4（胆固醇肉芽肿）的检测能力。



### 5.2 评价指标

1. **General Metrics:** Accuracy, AUC, Macro-F1.
2. **Tail Metrics:** 专门统计尾部类别（如人工模拟的Zero-shot类别）的 Recall 和 Precision。
3. **Semantic Consistency:** 使用检索指标 (Recall@K)，评估图像特征能否检索到正确的文本描述。

### 5.3 对比基线 (Baselines)

为了证明 Bi-CPL 的有效性，我们将与以下 SOTA 方法对比：

1. **3D-ResNet / 3D-DenseNet:** 纯视觉3D分类模型（无文本，无双侧设计）。
2. **ConVIRT / BioMedCLIP (3D adaptation):** 标准的医疗图文对比学习模型（无双侧设计，无原型矫正）。
3. **OLTR (Open Long-Tail Recognition):** 传统的长尾学习方法（重采样/重加权）。

### 5.4 预期结果

我们假设 Bi-CPL 将在以下方面展现显著优势：

* **不对称感知:** A3B 模块将使模型在早期微小病变的检测上优于单侧模型，热力图 (CAM) 将精准聚焦于患侧与健侧的差异区（如听骨链的微小吸收）。
* **长尾泛化:** 通过文本引导的原型，模型将在未见过的类别（模拟 Label 4）上达到可用的分类精度（预计 Zero-shot AUC > 0.75），远超随机猜测。
* **数据效率:** 相比全监督方法，Bi-CPL 在仅使用10%标签数据的情况下，依靠大量未标注图文对的预训练，仍能保持较高的性能。

---

## 6. 可行性与技术路线图

### 6.1 技术可行性分析

* **数据量:** 4000+例双侧数据（即8000+个耳部体积）对于3D预训练是充足的。文本报告虽然非结构化，但 CMBERT 对中文医疗文本有极强的解析能力。
* **算力需求:** 3D模型显存占用大。我们将采用 Mixed Precision Training (FP16) 和 Gradient Checkpointing 技术。DCFormer 架构本身即为高效设计。预计4块 RTX3090 或 A100 即可完成训练。
* **零样本逻辑:** 胆固醇肉芽肿的影像特征（膨胀性、囊性）与胆脂瘤（侵蚀性）在形态学上有显著差异，这种差异在文本描述中体现得淋漓尽致，因此文本引导的视觉区分在理论上是完全成立的。

### 6.2 实施步骤

1. **Month 1-2:** 数据清洗，NLP流水线搭建（提取实体），3D图像配准与预处理。
2. **Month 3:** 搭建 Bi-CPL 骨干，进行无监督的图文对比预训练 (Pre-training)。
3. **Month 4:** 引入双侧注意力模块与原型分类头，进行微调 (Fine-tuning)。
4. **Month 5:** 进行长尾/零样本模拟实验，消融实验 (Ablation Study)。
5. **Month 6:** 整理结果，撰写论文，可视化 Attention Map。

---

## 7. 结论

本研究方案提出了一种深度融合放射学先验知识（双侧对称性）与语义知识（影像报告）的3D医疗影像分析新范式。Bi-CPL 不仅能够提升常见耳科疾病的诊断精度，更通过文本原型的桥接作用，巧妙地解决了长尾罕见病数据缺失的难题。该方案完全基于现有数据，无需额外标注，具有极高的临床转化潜力和学术研究价值，有望为缺乏大规模标注数据的医疗AI领域提供一条切实可行的技术路径。

### 核心参考文献逻辑支撑:

* **双侧对称性价值:** 参考文献 [15] 证明了孪生网络在骨盆X光中利用对称性检测骨折的有效性；[14] 展示了乳腺钼靶中双侧不对称性对风险预测的贡献。
* **长尾与零样本策略:** 参考文献 [10] 和 [11] 提供了利用文本生成原型来锚定视觉特征的理论基础；[17] 验证了CLIP类模型在MRI脑肿瘤分类中优于传统少样本学习。
* **3D视觉-语言架构:** 参考文献 [5] (Med3DVLM) 提供了处理3D体积数据与文本对齐的高效架构参考 (DCFormer, SigLIP)。
* **病理与影像特征:** 参考文献 [18] 提供了区分胆脂瘤与胆固醇肉芽肿的关键医学证据，是构建文本 Prompt 的基础。

---

## 引用的著作

1. Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography. arXiv. [https://arxiv.org/html/2409.18119v1](https://arxiv.org/html/2409.18119v1)
2. MedCLIP: Contrastive Learning from Unpaired Medical Images and Text. ACL Anthology. [https://aclanthology.org/2022.emnlp-main.256.pdf](https://aclanthology.org/2022.emnlp-main.256.pdf)
3. Contrastive Learning of Medical Visual Representations from Paired Images and Text. [https://proceedings.mlr.press/v182/zhang22a/zhang22a.pdf](https://proceedings.mlr.press/v182/zhang22a/zhang22a.pdf)
4. BiomedCLIP: Advanced Medical Image-Text Model for Healthcare AI. [https://dr7.ai/biomedclip](https://dr7.ai/biomedclip)
5. Med3DVLM: An Efficient Vision-Language Model for 3D Medical Image Analysis. ResearchGate.
6. FeLoRA-SPP: Parameter-Efficient Fine-Tuning of 3D Multimodal LLMs. OpenReview.
7. Adapting Vision-Language Models for 3D CT/MRI Understanding on PMBB via Slice Selection and Explanation Analysis. ICCVW 2025.
8. Learning Prototype Classifiers for Long-Tailed Recognition. IJCAI.
9. ProCo: Prototype-aware Contrastive Learning for Long-tailed Medical Image Classification. MICCAI 2022.
10. TASA: Text-Anchored State-Space Alignment for Long-Tailed Image Classification. MDPI.
11. Prototype-Guided Zero-Shot Medical Image Segmentation with Large Vision-Language Models. MDPI.
12. Zero-Training Task-Specific Model Synthesis for Few-Shot Medical Image Classification. arXiv.
13. Using Deep Siamese Neural Networks for Detection of Brain Asymmetries Associated with Alzheimer's Disease. PMC.
14. AsymMirai: Interpretable Mammography-based Deep Learning Model for 1-5-year Breast Cancer Risk Prediction. Radiology.
15. Anatomy-Aware Siamese Network: Exploiting Semantic Asymmetry for Accurate Pelvic Fracture Detection in X-Ray Images. Johns Hopkins University.
16. Learning to Summarize Chinese Radiology Findings With a Pre-Trained Encoder. ResearchGate.
17. Few-Shot and Zero-Shot Learning for MRI Brain Tumor Classification Using CLIP and Vision Transformers. PubMed Central.
18. Final Diagnosis -- Case 64. UPMC Pathology.
19. Cholesterol granuloma | Radiology Reference Article. Radiopaedia.
20. Cholesteatoma | Radiology Reference Article. Radiopaedia.